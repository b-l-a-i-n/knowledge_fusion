{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "id": "T_rC1qZqRYIc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import textwrap\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/uhh-lt/TextGraphs17-shared-task.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "id": "Qi9dgEnWLuZJ"
   },
   "outputs": [],
   "source": [
    "test_file_path = \"../TextGraphs17-shared-task/data/tsv/test.tsv\"\n",
    "train_file_path = \"../TextGraphs17-shared-task/data/tsv/train.tsv\"\n",
    "\n",
    "df_test = pd.read_csv(test_file_path, sep=\"\\t\")\n",
    "df_train = pd.read_csv(train_file_path, sep=\"\\t\")\n",
    "\n",
    "id2ws = {}\n",
    "ws_df = pd.read_csv(\"../data/web_search_results_ddgo.csv\", index_col=0)\n",
    "for idx, row in ws_df.iterrows():\n",
    "    id2ws[row[\"questionEntityId\"]] = row[\"web_search_response\"]\n",
    "\n",
    "id2d = {}\n",
    "df_descriptions = pd.read_csv(\"../data/wikidata_descriptions.csv\", index_col=0)\n",
    "for idx, row in df_descriptions.iterrows():\n",
    "    id2d[row[\"answerEntityId\"]] = row[\"description\"]\n",
    "\n",
    "df_train[\"web_search\"] = df_train[\"questionEntityId\"].apply(lambda x: id2ws[x] if x not in [\"NF\", \"ND\"] else '')\n",
    "df_test[\"web_search\"] = df_test[\"questionEntityId\"].apply(lambda x: id2ws[x] if x not in [\"NF\", \"ND\"] else '')\n",
    "\n",
    "df_train[\"description\"] = df_train[\"answerEntityId\"].apply(lambda x: id2d[x])\n",
    "df_test[\"description\"] = df_test[\"answerEntityId\"].apply(lambda x: id2d[x])\n",
    "\n",
    "SEP_TOKEN = \"</s>\"\n",
    "\n",
    "def linearize_graph(graph):\n",
    "    nodes = {node['id']: f\"{node['label']} ({node['type']}, {node['name_']})\" for node in graph['nodes']}\n",
    "    edges = []\n",
    "    for link in graph['links']:\n",
    "        source_node = nodes[link['source']]\n",
    "        target_node = nodes[link['target']]\n",
    "        label = link['label']\n",
    "        edges.append(f\"{source_node} - {label} -> {target_node}\")\n",
    "    return '; '.join(edges)\n",
    "\n",
    "df_test[\"graph\"] = df_test[\"graph\"].apply(eval)\n",
    "df_train[\"graph\"] = df_train[\"graph\"].apply(eval)\n",
    "\n",
    "df_test[\"linearized_graph\"] = df_test[\"graph\"].apply(linearize_graph)\n",
    "df_train[\"linearized_graph\"] = df_train[\"graph\"].apply(linearize_graph)\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*shrugs* I don't really feel like telling you. Maybe I'm a mysterious stranger, or maybe I'm just a lazy AI who can't be bothered to come up with a decent response. Either way, you're not getting any useful information out of me.\""
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_content(\"Кто ты?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "id": "zQJyIcjKGFk1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_content(text):\n",
    "    url = \"http://0.0.0.0:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "            \"model\": \"/archive/beliakin/hub/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/359ec69a0f92259a3cd2da3bb01d31e16c260cfc/\",\n",
    "            \"messages\": [ {\"role\": \"system\", \"content\": \"You are **not** a helpful assistant.\"}, {\"role\": \"user\",\"content\": text}],\n",
    "        \"max_tokens\": 256,\"temperature\": 0}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return text\n",
    "\n",
    "def get_websearch_results(question):\n",
    "  results = []\n",
    "  search = DuckDuckGoSearchResults()    \n",
    "  snippet_list = search.run(question)\n",
    "  splitted = snippet_list.split(\"], [\")\n",
    "\n",
    "  for a in splitted:\n",
    "    b = re.search(r'snippet:(.*?), title:', a).group(1)\n",
    "    results.append(b)\n",
    "\n",
    "\n",
    "  llama_string = \"\"\n",
    "  for id, res in enumerate(results):\n",
    "      llama_string+=f'{id+1}. {res}\\r\\n'\n",
    "      \n",
    "  return llama_string\n",
    "\n",
    "def predict(row):\n",
    "    message, decode_dict = get_context(row)\n",
    "    # print(message)\n",
    "    # print(message)\n",
    "    attempts = 5\n",
    "    res = False\n",
    "    idx = row['answerEntityId']\n",
    "    while not res:\n",
    "      try:\n",
    "        text = generate_content(message)\n",
    "        res = True\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error\")\n",
    "        time.sleep(20-attempts)\n",
    "        attempts -= 1\n",
    "\n",
    "      if attempts == 0:\n",
    "        text = \"Failed\"\n",
    "        res = True\n",
    "    return text, decode_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Entity/id prediction experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(row, entity=True):\n",
    "    if entity:\n",
    "      text = row[\"entity_id\"]\n",
    "      message = f\"What WikiData entity does WikiDataId {text} have? Return only WikiData entity.\"\n",
    "    else:\n",
    "      text = row[\"entity\"]\n",
    "      message = f\"What WikiDataID does '{text}' have? Return only WikiDataID.\"\n",
    "    attempts = 5\n",
    "    res = False\n",
    "    while not res:\n",
    "      try:\n",
    "        text = generate_content(message)\n",
    "        res = True\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error\")\n",
    "        time.sleep(20-attempts)\n",
    "        attempts -= 1\n",
    "\n",
    "      if attempts == 0:\n",
    "        text = \"No answer\"\n",
    "        res = True\n",
    "    return text\n",
    "\n",
    "def predict_correct(row, entity=True):\n",
    "    if entity:\n",
    "      label, correct_label = \"entity\", \"predicted_entity\"\n",
    "      question = f\"What WikiDataID does '{label}' have? Return only WikiDataID.\"\n",
    "    else:\n",
    "      label, correct_label = \"entity_id\", \"predicted_id\"\n",
    "      question = f\"What WikiData entity does WikiDataId {label} have? Return only WikiData entity.\"\n",
    "    text, correct_text = row[label], row[correct_label]\n",
    "    message = f\"\"\"You should rate the candidate answer and the correct answer. Return 1 if candidate answer corresponds to correct else return 0. Return only 1 if correct else 0. \\n Question: {question} \\n Candidate answer: {text} \\n Correct answer: {correct_text} \\n Is candidate answer correct?\"\"\"\n",
    "    attempts = 5\n",
    "    res = False\n",
    "    while not res:\n",
    "      try:\n",
    "        text = generate_content(message)\n",
    "        res = True\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error\")\n",
    "        time.sleep(20-attempts)\n",
    "        attempts -= 1\n",
    "\n",
    "      if attempts == 0:\n",
    "        text = \"No answer\"\n",
    "        res = True\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XA7Eyn4gSZjV"
   },
   "outputs": [],
   "source": [
    "all_entity = []\n",
    "all_entity_id = []\n",
    "\n",
    "for entity, entity_id in zip(df[\"answerEntity\"].values, df[\"answerEntityId\"].values):\n",
    "    if ',' in entity_id:\n",
    "        for e, i in zip(entity.split(\",\"), entity_id.split(\",\")):\n",
    "            all_entity.append(e)\n",
    "            all_entity_id.append(i)\n",
    "    else:\n",
    "        all_entity.append(entity)\n",
    "        all_entity_id.append(entity_id)\n",
    "\n",
    "for entity, entity_id in zip(df[\"questionEntity\"].values, df[\"questionEntityId\"].values):\n",
    "    if ',' in entity_id:\n",
    "        for e, i in zip(entity.split(\",\"), entity_id.split(\",\")):\n",
    "            all_entity.append(e)\n",
    "            all_entity_id.append(i)\n",
    "    else:\n",
    "        all_entity.append(entity)\n",
    "        all_entity_id.append(entity_id)\n",
    "\n",
    "data = [(e, i) for e, i in zip(all_entity, all_entity_id)]\n",
    "df_ents = pd.DataFrame(data, columns=[\"entity\", \"entity_id\"]).drop_duplicates(\"entity_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruhollah Khomeini's return to Iran</td>\n",
       "      <td>Q7293530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruhollah Khomeini's letter to Mikhail Gorbachev</td>\n",
       "      <td>Q5952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruhollah Khomeini</td>\n",
       "      <td>Q38823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office of the Supreme Leader of Iran</td>\n",
       "      <td>Q16045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mohammad Reza Pahlavi and Soraya</td>\n",
       "      <td>Q63195813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23278</th>\n",
       "      <td>Pide and Prejudice</td>\n",
       "      <td>Q170583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23279</th>\n",
       "      <td>Elizabeth Bennet</td>\n",
       "      <td>Q2223341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>older sister</td>\n",
       "      <td>Q10082670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>Booker Award</td>\n",
       "      <td>Q160082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>P.H. Newby</td>\n",
       "      <td>Q531194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                entity   entity_id\n",
       "0                   Ruhollah Khomeini's return to Iran    Q7293530\n",
       "1      Ruhollah Khomeini's letter to Mikhail Gorbachev    Q5952984\n",
       "2                                    Ruhollah Khomeini      Q38823\n",
       "3                 Office of the Supreme Leader of Iran   Q16045000\n",
       "4                     Mohammad Reza Pahlavi and Soraya   Q63195813\n",
       "...                                                ...         ...\n",
       "23278                               Pide and Prejudice     Q170583\n",
       "23279                                 Elizabeth Bennet    Q2223341\n",
       "23280                                     older sister   Q10082670\n",
       "23281                                     Booker Award     Q160082\n",
       "23282                                       P.H. Newby     Q531194\n",
       "\n",
       "[23283 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kINPWlnUTJ6n"
   },
   "outputs": [],
   "source": [
    "limit = 10\n",
    "df_ents_test = df_ents.iloc[:limit, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "En-JM9AlZv7j",
    "outputId": "96eab006-a2ab-46d7-ba46-ae3daa2f319b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruhollah Khomeini's return to Iran</td>\n",
       "      <td>Q7293530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruhollah Khomeini's letter to Mikhail Gorbachev</td>\n",
       "      <td>Q5952984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruhollah Khomeini</td>\n",
       "      <td>Q38823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office of the Supreme Leader of Iran</td>\n",
       "      <td>Q16045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mohammad Reza Pahlavi and Soraya</td>\n",
       "      <td>Q63195813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahmoud Ahmadinejad</td>\n",
       "      <td>Q34448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hassan Rouhani</td>\n",
       "      <td>Q348144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ayatollah Khamenei's Foreign Policy Orientation</td>\n",
       "      <td>Q57483966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ayatollah Ali Khamenei speaks about Iranian pr...</td>\n",
       "      <td>Q18017728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ali Khamenei bibliography</td>\n",
       "      <td>Q50815843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              entity  entity_id\n",
       "0                 Ruhollah Khomeini's return to Iran   Q7293530\n",
       "1    Ruhollah Khomeini's letter to Mikhail Gorbachev   Q5952984\n",
       "2                                  Ruhollah Khomeini     Q38823\n",
       "3               Office of the Supreme Leader of Iran  Q16045000\n",
       "4                   Mohammad Reza Pahlavi and Soraya  Q63195813\n",
       "5                                Mahmoud Ahmadinejad     Q34448\n",
       "6                                     Hassan Rouhani    Q348144\n",
       "7    Ayatollah Khamenei's Foreign Policy Orientation  Q57483966\n",
       "8  Ayatollah Ali Khamenei speaks about Iranian pr...  Q18017728\n",
       "9                          Ali Khamenei bibliography  Q50815843"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ents_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "2XyTtj4rZEH4",
    "outputId": "48828e66-f744-45c9-d2cc-4a8f33eeff73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d271e64198a4ca18c97de0d6c06530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2202481/280757366.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ents_test[\"predicted_entity\"] = df_ents_test.progress_apply(lambda row: predict_label(row, entity=True), axis=1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df09fe893a884cb899f70e2ff7295930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2202481/280757366.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ents_test[\"predicted_id\"] = df_ents_test.progress_apply(lambda row: predict_label(row, entity=False), axis=1)\n",
      "/tmp/ipykernel_2202481/280757366.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ents_test[\"correct_entity\"] = df_ents_test.apply(lambda row: predict_correct(row, entity=True), axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_ents_test[\"predicted_entity\"] = df_ents_test.progress_apply(lambda row: predict_label(row, entity=True), axis=1)\n",
    "df_ents_test[\"predicted_id\"] = df_ents_test.progress_apply(lambda row: predict_label(row, entity=False), axis=1)\n",
    "df_ents_test[\"correct_entity\"] = df_ents_test.apply(lambda row: predict_correct(row, entity=True), axis=1)\n",
    "# df_ents_test[\"correct_id\"] = df_ents_test.apply(lambda row: predict_correct(row, entity=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>predicted_entity</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>correct_entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruhollah Khomeini's return to Iran</td>\n",
       "      <td>Q7293530</td>\n",
       "      <td>Borjomi Municipality</td>\n",
       "      <td>Q640544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruhollah Khomeini's letter to Mikhail Gorbachev</td>\n",
       "      <td>Q5952984</td>\n",
       "      <td>Budapest Ferenc Liszt International Airport</td>\n",
       "      <td>Q4117189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruhollah Khomeini</td>\n",
       "      <td>Q38823</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>Q131796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office of the Supreme Leader of Iran</td>\n",
       "      <td>Q16045000</td>\n",
       "      <td>The WikiData entity for WikiDataId Q16045000 i...</td>\n",
       "      <td>Q1048413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mohammad Reza Pahlavi and Soraya</td>\n",
       "      <td>Q63195813</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>Q211964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahmoud Ahmadinejad</td>\n",
       "      <td>Q34448</td>\n",
       "      <td>The WikiData entity for WikiDataId Q34448 is: ...</td>\n",
       "      <td>Q9176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hassan Rouhani</td>\n",
       "      <td>Q348144</td>\n",
       "      <td>Q348144 is an identifier for the entity \"Budap...</td>\n",
       "      <td>Q131741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ayatollah Khamenei's Foreign Policy Orientation</td>\n",
       "      <td>Q57483966</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>Q106304634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ayatollah Ali Khamenei speaks about Iranian pr...</td>\n",
       "      <td>Q18017728</td>\n",
       "      <td>The WikiData entity for WikiDataId Q18017728 i...</td>\n",
       "      <td>Q6641445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ali Khamenei bibliography</td>\n",
       "      <td>Q50815843</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>Q106313432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              entity  entity_id  \\\n",
       "0                 Ruhollah Khomeini's return to Iran   Q7293530   \n",
       "1    Ruhollah Khomeini's letter to Mikhail Gorbachev   Q5952984   \n",
       "2                                  Ruhollah Khomeini     Q38823   \n",
       "3               Office of the Supreme Leader of Iran  Q16045000   \n",
       "4                   Mohammad Reza Pahlavi and Soraya  Q63195813   \n",
       "5                                Mahmoud Ahmadinejad     Q34448   \n",
       "6                                     Hassan Rouhani    Q348144   \n",
       "7    Ayatollah Khamenei's Foreign Policy Orientation  Q57483966   \n",
       "8  Ayatollah Ali Khamenei speaks about Iranian pr...  Q18017728   \n",
       "9                          Ali Khamenei bibliography  Q50815843   \n",
       "\n",
       "                                    predicted_entity predicted_id  \\\n",
       "0                               Borjomi Municipality      Q640544   \n",
       "1        Budapest Ferenc Liszt International Airport     Q4117189   \n",
       "2                                           Budapest      Q131796   \n",
       "3  The WikiData entity for WikiDataId Q16045000 i...     Q1048413   \n",
       "4                                      Boris Johnson      Q211964   \n",
       "5  The WikiData entity for WikiDataId Q34448 is: ...        Q9176   \n",
       "6  Q348144 is an identifier for the entity \"Budap...      Q131741   \n",
       "7                                      Boris Johnson   Q106304634   \n",
       "8  The WikiData entity for WikiDataId Q18017728 i...     Q6641445   \n",
       "9                                      Boris Johnson   Q106313432   \n",
       "\n",
       "  correct_entity  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ents_test.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You must follow the rules before answering:\n",
    "- A question and its answer options will be provided.\n",
    "- The question has only one correct option.\n",
    "- The correct answer is always given.\n",
    "- Write only the number of the correct option.\n",
    "- If you do not know the answer, write only the number of the most likely one.\n",
    "- \n",
    "\n",
    "{additional_context}\n",
    "Question: '{question}'\n",
    "Options:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = \"\"\"You must follow the rules before answering:\n",
    "- A question and its answer options will be provided.\n",
    "- The question has only one correct option.\n",
    "- The correct answer is always given.\n",
    "- Write only the number of the correct option in bracket: [].\n",
    "- If you do not know the answer, write only the number of the most likely one in bracket: [].\n",
    "{additional_context}\n",
    "Question: '{question}'\n",
    "Options:\n",
    "\"\"\"\n",
    "\n",
    "# PROMPT = \"\"\"You must follow the rules before answering:\n",
    "# - A question and its answer options will be provided.\n",
    "# - The question has only one correct option.\n",
    "# - The correct answer is always given.\n",
    "# - Write only the WikiDataID of the correct option.\n",
    "# - If you do not know the answer, write only the WikiDataID of the most likely one.\n",
    "# {additional_context}\n",
    "# Question: '{question}'\n",
    "# Options:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(ds, include_graph=False, include_description=True, use_web_search=True):\n",
    "    additional_context = ''\n",
    "    if use_web_search:\n",
    "        search_results = row[\"web_search\"].iloc[0]\n",
    "        additional_context += f\"\\nBelow are the facts that might be relevant to answer the question:\\n{search_results}\\n\"\n",
    "        \n",
    "    message = PROMPT.format(question=row[\"question\"].iloc[0], additional_context=additional_context)\n",
    "        \n",
    "    decode_dict = {}\n",
    "    for idx, (answer, wiki_id, graph, description) in enumerate(zip(ds['answerEntity'], ds['answerEntityId'], ds[\"linearized_graph\"], ds[\"description\"])):\n",
    "        decode_dict[idx] = wiki_id\n",
    "        data = {\"answer\":answer, \"WikiDataID\":wiki_id}\n",
    "        if include_graph:\n",
    "            data[\"wikidata_graph\"] = graph\n",
    "        if include_description:\n",
    "            data[\"description\"] = description\n",
    "        message += str(idx) + \". \" + json.dumps(data) + \"\\n\"\n",
    "    # print(message)\n",
    "    return message, decode_dict\n",
    "\n",
    "def get_answers(text):\n",
    "    matches = re.findall(r'\\[\\d+(?:,\\s*\\d+)*\\]', text)\n",
    "    if len(matches) == 0: \n",
    "        matches = re.findall(r'\\d+', text)\n",
    "    preds = []\n",
    "    for match in matches:\n",
    "        preds.extend([int(i.replace(\"[\",'').replace(']','')) for i in match.split(\",\") if i != ''])\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_predictions(preds, df, use_digits=True):\n",
    "    if use_digits:\n",
    "        preds['prediction'] = preds[\"prediction\"].apply(get_answers)\n",
    "        preds['match_dict'] = preds['match_dict'].apply(eval)\n",
    "        preds['prediction'] = [[x['match_dict'][j] for j in x['prediction'] if j in x['match_dict']] for i, x in preds.iterrows()]\n",
    "        \n",
    "        new_df = {\"prediction\": [], \"questionEntityId\": [], \"answerEntityId\": []}\n",
    "        for i, row in preds.iterrows():\n",
    "            for item, id in row['match_dict'].items():\n",
    "                new_df[\"answerEntityId\"].append(id)\n",
    "                new_df[\"prediction\"].append(id in row['prediction'])\n",
    "                new_df[\"questionEntityId\"].append(row['questionEntityId'])\n",
    "        result = pd.DataFrame(new_df).sort_values(by=[\"questionEntityId\", \"answerEntityId\"])\n",
    "    else:\n",
    "        ans_dict = {}\n",
    "        for idx, row in preds.reset_index().iterrows():\n",
    "            ans_dict[row[\"questionEntityId\"]] = row[\"prediction\"]\n",
    "        result = df.copy()\n",
    "        result[\"prediction\"] = result.apply(lambda row: 1 if row[\"answerEntityId\"] in ans_dict[row[\"questionEntityId\"]] else 0, axis=1)\n",
    "        # df_final_preds[\"output\"] = df_final_preds.apply(lambda row: ans_dict[row[\"question\"]], axis=1)\n",
    "    result = result.sort_values(by=[\"questionEntityId\", \"answerEntityId\"]).reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb25e0412549fa93846a665f493317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "all_rows = []\n",
    "\n",
    "for question, row in tqdm(df_train.groupby(\"question\")):\n",
    "    text, match = predict(row)\n",
    "    all_rows.append({\"questionEntityId\":row[\"questionEntityId\"].values[0], \"prediction\": text, \"match_dict\":match})\n",
    "\n",
    "preds_name = \"llama_70B_train_descriptions_ws_br.csv\"\n",
    "predictions_df = pd.DataFrame(all_rows\n",
    "predictions_df.to_csv(preds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_name = \"llama_70B_train_descriptions_ws_br.csv\"\n",
    "\n",
    "predictions_df = pd.read_csv(preds_name, index_col=0)\n",
    "predictions_df_v2 = pd.read_csv(preds_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.96      0.97     34213\n",
      "        True       0.65      0.71      0.68      3459\n",
      "\n",
      "    accuracy                           0.94     37672\n",
      "   macro avg       0.81      0.83      0.82     37672\n",
      "weighted avg       0.94      0.94      0.94     37672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_predictions(predictions_df.copy(), df_train.copy(), use_digits=True)\n",
    "df_train_sorted = df_train.sort_values(by=[\"questionEntityId\", \"answerEntityId\"]).reset_index(drop=True)\n",
    "print(classification_report(result['prediction'], df_train_sorted[\"correct\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66902bacb5764769b52f000a6856db03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "all_rows = []\n",
    "\n",
    "for question, row in tqdm(df_test.groupby(\"question\")):\n",
    "    text, match = predict(row)\n",
    "    all_rows.append({\"questionEntityId\":row[\"questionEntityId\"].values[0], \"prediction\": text, \"match_dict\":match})\n",
    "\n",
    "preds_name = \"llama_70B_test_descriptions_ws_br.csv\"\n",
    "predictions_df = pd.DataFrame(all_rows)\n",
    "predictions_df.to_csv(preds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionEntityId</th>\n",
       "      <th>prediction</th>\n",
       "      <th>match_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1213715</td>\n",
       "      <td>[9]</td>\n",
       "      <td>{0: 'Q300370', 1: 'Q1764445', 2: 'Q772435', 3:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q458</td>\n",
       "      <td>[None]</td>\n",
       "      <td>{0: 'Q31', 1: 'Q171348', 2: 'Q142', 3: 'Q47774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q99416119</td>\n",
       "      <td>[7]</td>\n",
       "      <td>{0: 'Q1415970', 1: 'Q921957', 2: 'Q687559', 3:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q38111, Q19020</td>\n",
       "      <td>[5]</td>\n",
       "      <td>{0: 'Q1988', 1: 'Q2014', 2: 'Q2019', 3: 'Q1998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q34836, Q11696, Q91</td>\n",
       "      <td>[0]</td>\n",
       "      <td>{0: 'Q91', 1: 'Q11816', 2: 'Q55725954', 3: 'Q3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Q750</td>\n",
       "      <td>[7]</td>\n",
       "      <td>{0: 'Q74457482', 1: 'Q315975', 2: 'Q96139893',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Q155223, Q131364, Q131371</td>\n",
       "      <td>[0]</td>\n",
       "      <td>{0: 'Q131371', 1: 'Q4817541', 2: 'Q17603350', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Q170583, Q2223341, Q10082670</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{0: 'Q318399', 1: 'Q4390263', 2: 'Q4303435', 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Q160082, Q531194</td>\n",
       "      <td>[3]</td>\n",
       "      <td>{0: 'Q1978467', 1: 'Q387480', 2: 'Q77002510', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Q98973368</td>\n",
       "      <td>[8]</td>\n",
       "      <td>{0: 'Q79692', 1: 'Q238137', 2: 'Q18258387', 3:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 questionEntityId prediction  \\\n",
       "0                        Q1213715        [9]   \n",
       "1                            Q458     [None]   \n",
       "2                       Q99416119        [7]   \n",
       "3                  Q38111, Q19020        [5]   \n",
       "4             Q34836, Q11696, Q91        [0]   \n",
       "..                            ...        ...   \n",
       "995                          Q750        [7]   \n",
       "996     Q155223, Q131364, Q131371        [0]   \n",
       "997  Q170583, Q2223341, Q10082670        [1]   \n",
       "998              Q160082, Q531194        [3]   \n",
       "999                     Q98973368        [8]   \n",
       "\n",
       "                                            match_dict  \n",
       "0    {0: 'Q300370', 1: 'Q1764445', 2: 'Q772435', 3:...  \n",
       "1    {0: 'Q31', 1: 'Q171348', 2: 'Q142', 3: 'Q47774...  \n",
       "2    {0: 'Q1415970', 1: 'Q921957', 2: 'Q687559', 3:...  \n",
       "3    {0: 'Q1988', 1: 'Q2014', 2: 'Q2019', 3: 'Q1998...  \n",
       "4    {0: 'Q91', 1: 'Q11816', 2: 'Q55725954', 3: 'Q3...  \n",
       "..                                                 ...  \n",
       "995  {0: 'Q74457482', 1: 'Q315975', 2: 'Q96139893',...  \n",
       "996  {0: 'Q131371', 1: 'Q4817541', 2: 'Q17603350', ...  \n",
       "997  {0: 'Q318399', 1: 'Q4390263', 2: 'Q4303435', 3...  \n",
       "998  {0: 'Q1978467', 1: 'Q387480', 2: 'Q77002510', ...  \n",
       "999  {0: 'Q79692', 1: 'Q238137', 2: 'Q18258387', 3:...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_name = \"llama_70B_test_descriptions_ws_br.csv\"\n",
    "predictions_df = pd.read_csv(preds_name, index_col=0)\n",
    "result = get_predictions(predictions_df.copy(), df_test, use_digits=True).sort_values(by=[\"questionEntityId\", \"answerEntityId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(data={\"sample_id\": df_test.sort_values(by=[\"questionEntityId\", \"answerEntityId\"])['sample_id'],\n",
    "                                   'prediction': result.sort_values(by=[\"questionEntityId\", \"answerEntityId\"])['prediction'].astype(int)})\n",
    "submission_df = submission_df.sort_values(by=\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission_llama_70B_description_ws_br.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>10956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>10957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>10958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>10959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id  prediction\n",
       "0              0           0\n",
       "1              1           1\n",
       "2              2           0\n",
       "3              3           0\n",
       "4              4           0\n",
       "...          ...         ...\n",
       "10956      10956           0\n",
       "10957      10957           0\n",
       "10958      10958           0\n",
       "10959      10959           0\n",
       "10960      10960           0\n",
       "\n",
       "[10961 rows x 2 columns]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with WikiDataId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(row):\n",
    "    question, answ, wiki_id = row['question'], row['answerEntity'], row['answerEntityId']\n",
    "    message = f\"\"\"Please answer the following question, the answer should be a WikiDataID.\n",
    "Question: '{question.iloc[0]}'\n",
    "Choose the correct answer. Return only WikiDataID.\\n\"\"\"\n",
    "\n",
    "def get_context(row):\n",
    "    question, answ, id = row['question'], row['answerEntity'], row['answerEntityId']\n",
    "    graph = [linearize_graph(g) for g in row['graph']]\n",
    "    message = f\"\"\"Please answer the following question; the answer should be a WikiDataID.\n",
    "Question: '{question.iloc[0]}'\n",
    "Choose the correct option and write only WikiDataID.\"\"\"\n",
    "    message += \"\\n\".join([f\"{a} {i}\" for a, i, g in zip(answ, id, graph)])\n",
    "    return message, _\n",
    "#     message = f\"\"\"You must follow the rules before answering:\n",
    "# - A question and its answer options will be provided.\n",
    "# - There can be multiple correct options.\n",
    "# - The correct answer is always given.\n",
    "# - For each correct option, write only its letter.\n",
    "# - If you do not know the answer, propose the most likely ones.\n",
    "\n",
    "# Question: '{question.iloc[0]}'\n",
    "# Options:\n",
    "# \"\"\"\n",
    "    # decode_dict = {}\n",
    "    # for idx, (a, i) in enumerate(zip(answ, wiki_id)):\n",
    "    #     decode_dict[idx] = i\n",
    "    #     data = {\"answer\":a, \"WikiDataID\":i}\n",
    "    #     message += str(idx) + \". \" + json.dumps(data) + \"\\n\"\n",
    "    # return message, decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baec82ef2aa4363b1c64746ac61a6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_predictions = df_test[['question', 'answerEntity', 'answerEntityId', \"graph\"]].groupby('question').progress_apply(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(\"llama_70B_base_prediction_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict = {}\n",
    "for idx, answer in df_predictions.reset_index().iterrows():\n",
    "    ans_dict[answer[\"question\"]] = answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "ge0ewXzxS8Xv"
   },
   "outputs": [],
   "source": [
    "df_final_preds = df_test.copy()\n",
    "df_final_preds[\"prediction\"] = df_final_preds.apply(lambda row: 1 if row[\"answerEntityId\"] in ans_dict[row[\"question\"]] else 0, axis=1)\n",
    "df_final_preds[\"output\"] = df_final_preds.apply(lambda row: ans_dict[row[\"question\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3308498/3905325266.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(df[df_final_preds[\"prediction\"] == df_train['correct']])/len(df)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9394444101741616"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df_final_preds[\"prediction\"] == df_train['correct']])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "dh1blrL1WDiK",
    "outputId": "89ecb71b-af35-4a90-d818-9ca5eb40fe9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>question</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>answerEntityId</th>\n",
       "      <th>questionEntityId</th>\n",
       "      <th>groundTruthAnswerEntityId</th>\n",
       "      <th>correct</th>\n",
       "      <th>graph</th>\n",
       "      <th>linearized_graph</th>\n",
       "      <th>prediction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Whst is the name of the head of state and high...</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Ruhollah Khomeini's return to Iran</td>\n",
       "      <td>Office of the Supreme Leader of Iran</td>\n",
       "      <td>Q7293530</td>\n",
       "      <td>Q794</td>\n",
       "      <td>Q16045000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'nodes': [{'type': 'QUESTIONS_ENTITY', 'name_...</td>\n",
       "      <td>Iran (QUESTIONS_ENTITY, Q794) - country -&gt; Ira...</td>\n",
       "      <td>0</td>\n",
       "      <td>The correct answer is:\\n\\n10. {\"answer\": \"Ali ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                           question  \\\n",
       "0          0  Whst is the name of the head of state and high...   \n",
       "\n",
       "  questionEntity                        answerEntity  \\\n",
       "0           Iran  Ruhollah Khomeini's return to Iran   \n",
       "\n",
       "                groundTruthAnswerEntity answerEntityId questionEntityId  \\\n",
       "0  Office of the Supreme Leader of Iran       Q7293530             Q794   \n",
       "\n",
       "  groundTruthAnswerEntityId  correct  \\\n",
       "0                 Q16045000    False   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'nodes': [{'type': 'QUESTIONS_ENTITY', 'name_...   \n",
       "\n",
       "                                    linearized_graph  prediction  \\\n",
       "0  Iran (QUESTIONS_ENTITY, Q794) - country -> Ira...           0   \n",
       "\n",
       "                                              output  \n",
       "0  The correct answer is:\\n\\n10. {\"answer\": \"Ali ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_preds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "G9dFXBCXcINY",
    "outputId": "1b3f8da7-547b-4b2f-f53c-001844ef78eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>10956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>10957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>10958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>10959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id  prediction\n",
       "0              0           0\n",
       "1              1           0\n",
       "2              2           0\n",
       "3              3           0\n",
       "4              4           0\n",
       "...          ...         ...\n",
       "10956      10956           0\n",
       "10957      10957           0\n",
       "10958      10958           0\n",
       "10959      10959           1\n",
       "10960      10960           0\n",
       "\n",
       "[10961 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(data={\"sample_id\": df_final_preds['sample_id'], 'prediction': df_final_preds['prediction']})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10959"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(submission_df_1[\"prediction\"] == submission_df[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.prediction.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "NM_wrYntcIQs"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission_test_old_prompt.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final_preds[\"gt_values\"] = (df_final_preds[\"answerEntityId\"] == df_final_preds[\"groundTruthAnswerEntityId\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_preds.to_csv(\"preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_correct = df_final_preds[(df_final_preds[\"answerEntityId\"] == df_final_preds[\"groundTruthAnswerEntityId\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [37672, 10961]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[338], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcorrect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2592\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2458\u001b[0m     {\n\u001b[1;32m   2459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2483\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2484\u001b[0m ):\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \n\u001b[1;32m   2487\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2592\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2595\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37672, 10961]"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_train[\"correct\"].values, result[\"prediction\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = df_final_preds[df_final_preds[\"gt_values\"] != df_final_preds[\"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fd929aecd50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_failed.groupby(\"question\").apply(lambda ds: if 1 in ds.is_correct.values)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
